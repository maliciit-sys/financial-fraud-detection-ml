{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, average_precision_score,\n",
    "    f1_score, precision_score, recall_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# ===== 1. LOAD DATA =====\n",
    "print(\"Loading data...\")\n",
    "X_train = pd.read_csv('X_train_fixed.csv')\n",
    "y_train = pd.read_csv('y_train_fixed.csv').values.flatten()\n",
    "X_val = pd.read_csv('X_val_fixed.csv')\n",
    "y_val = pd.read_csv('y_val_fixed.csv').values.flatten()\n",
    "X_test = pd.read_csv('X_test_fixed.csv')\n",
    "y_test = pd.read_csv('y_test_fixed.csv').values.flatten()\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]:,} samples ({y_train.mean()*100:.2f}% fraud)\")\n",
    "print(f\"Val:   {X_val.shape[0]:,} samples ({y_val.mean()*100:.2f}% fraud)\")\n",
    "print(f\"Test:  {X_test.shape[0]:,} samples ({y_test.mean()*100:.2f}% fraud)\")\n",
    "\n",
    "# ===== 2. CALCULATE CLASS WEIGHT =====\n",
    "fraud_count = y_train.sum()\n",
    "non_fraud_count = len(y_train) - fraud_count\n",
    "scale_pos_weight = non_fraud_count / fraud_count\n",
    "print(f\"\\nClass imbalance ratio: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# ===== 3. CONFIGURE XGBOOST WITH CUDA =====\n",
    "print(\"\\nConfiguring XGBoost with CUDA...\")\n",
    "\n",
    "params = {\n",
    "    # GPU settings\n",
    "    'device': 'cuda',\n",
    "    'tree_method': 'hist',\n",
    "\n",
    "    # Model parameters\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': ['auc', 'aucpr', 'logloss'],\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "\n",
    "    # Tree parameters\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 5,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "\n",
    "    # Regularization\n",
    "    'reg_alpha': 0.1,      # L1\n",
    "    'reg_lambda': 1.0,     # L2\n",
    "\n",
    "    # Learning\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 500,\n",
    "\n",
    "    # Reproducibility\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "print(\"Parameters configured:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# ===== 4. CREATE DMatrix (XGBoost's optimized data structure) =====\n",
    "print(\"\\nCreating DMatrix for GPU...\")\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# ===== 5. TRAIN MODEL =====\n",
    "print(\"\\nTraining XGBoost model on GPU...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Training with early stopping\n",
    "evals = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=500,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=30,\n",
    "    verbose_eval=25  # Print every 25 rounds\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n✓ Training complete in {training_time:.1f} seconds\")\n",
    "print(f\"Best iteration: {model.best_iteration}\")\n",
    "\n",
    "# ===== 6. GET PREDICTIONS =====\n",
    "print(\"\\nGenerating predictions...\")\n",
    "y_probs = model.predict(dtest)\n",
    "print(f\"Probability range: {y_probs.min():.4f} to {y_probs.max():.4f}\")\n",
    "print(f\"Probability mean: {y_probs.mean():.4f}\")\n",
    "print(f\"Probability std: {y_probs.std():.4f}\")\n",
    "\n",
    "# ===== 7. THRESHOLD OPTIMIZATION =====\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"THRESHOLD OPTIMIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "thresholds = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "results = []\n",
    "for thresh in thresholds:\n",
    "    preds = (y_probs >= thresh).astype(int)\n",
    "\n",
    "    tp = ((preds == 1) & (y_test == 1)).sum()\n",
    "    fp = ((preds == 1) & (y_test == 0)).sum()\n",
    "    tn = ((preds == 0) & (y_test == 0)).sum()\n",
    "    fn = ((preds == 0) & (y_test == 1)).sum()\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    results.append({\n",
    "        'threshold': thresh,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'predicted_frauds': preds.sum(),\n",
    "        'true_positives': tp,\n",
    "        'false_positives': fp,\n",
    "        'false_negatives': fn\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'Thresh':<8} {'Precision':<12} {'Recall':<10} {'F1':<10} {'Pred Frauds':<14} {'TP':<10} {'FP':<12} {'FN':<10}\")\n",
    "print(\"-\" * 100)\n",
    "for r in results:\n",
    "    print(f\"{r['threshold']:<8.2f} {r['precision']:<12.4f} {r['recall']:<10.4f} {r['f1']:<10.4f} {r['predicted_frauds']:<14,} {r['true_positives']:<10,} {r['false_positives']:<12,} {r['false_negatives']:<10,}\")\n",
    "\n",
    "# Find optimal threshold\n",
    "best_result = max(results, key=lambda x: x['f1'])\n",
    "print(f\"\\n✓ Optimal Threshold (Max F1): {best_result['threshold']}\")\n",
    "print(f\"  Precision: {best_result['precision']:.4f}\")\n",
    "print(f\"  Recall: {best_result['recall']:.4f}\")\n",
    "print(f\"  F1: {best_result['f1']:.4f}\")\n",
    "print(f\"  False Positives: {best_result['false_positives']:,}\")\n",
    "\n",
    "# ===== 8. DETAILED EVALUATION =====\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"DETAILED EVALUATION AT THRESHOLD = {best_result['threshold']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "optimal_preds = (y_probs >= best_result['threshold']).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, optimal_preds, target_names=['Non-Fraud', 'Fraud'], digits=4))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "pr_auc = average_precision_score(y_test, y_probs)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"PR-AUC Score: {pr_auc:.4f}\")\n",
    "\n",
    "# ===== 9. FEATURE IMPORTANCE =====\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "importance = model.get_score(importance_type='gain')\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': importance.keys(),\n",
    "    'importance': importance.values()\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "for idx, row in importance_df.head(10).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.2f}\")\n",
    "\n",
    "# ===== 10. VISUALIZATIONS =====\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Confusion Matrix\n",
    "cm = confusion_matrix(y_test, optimal_preds)\n",
    "sns.heatmap(cm, annot=True, fmt=',d', cmap='Blues', ax=axes[0, 0],\n",
    "            xticklabels=['Non-Fraud', 'Fraud'],\n",
    "            yticklabels=['Non-Fraud', 'Fraud'])\n",
    "axes[0, 0].set_ylabel('Actual')\n",
    "axes[0, 0].set_xlabel('Predicted')\n",
    "axes[0, 0].set_title(f'Confusion Matrix (threshold={best_result[\"threshold\"]})', fontweight='bold')\n",
    "\n",
    "# Plot 2: ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "axes[0, 1].plot(fpr, tpr, linewidth=2, label=f'XGBoost (AUC={roc_auc:.3f})')\n",
    "axes[0, 1].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "axes[0, 1].set_xlabel('False Positive Rate')\n",
    "axes[0, 1].set_ylabel('True Positive Rate')\n",
    "axes[0, 1].set_title('ROC Curve', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Precision-Recall Curve\n",
    "precisions_curve, recalls_curve, _ = precision_recall_curve(y_test, y_probs)\n",
    "axes[0, 2].plot(recalls_curve, precisions_curve, linewidth=2, label=f'XGBoost (AP={pr_auc:.3f})')\n",
    "axes[0, 2].axhline(y=y_test.mean(), color='k', linestyle='--', label=f'Baseline ({y_test.mean():.3f})')\n",
    "axes[0, 2].set_xlabel('Recall')\n",
    "axes[0, 2].set_ylabel('Precision')\n",
    "axes[0, 2].set_title('Precision-Recall Curve', fontweight='bold')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: Threshold vs Metrics\n",
    "thresholds_plot = [r['threshold'] for r in results]\n",
    "precisions_plot = [r['precision'] for r in results]\n",
    "recalls_plot = [r['recall'] for r in results]\n",
    "f1s_plot = [r['f1'] for r in results]\n",
    "\n",
    "axes[1, 0].plot(thresholds_plot, precisions_plot, 'b-o', label='Precision', linewidth=2)\n",
    "axes[1, 0].plot(thresholds_plot, recalls_plot, 'g-s', label='Recall', linewidth=2)\n",
    "axes[1, 0].plot(thresholds_plot, f1s_plot, 'r-^', label='F1', linewidth=2)\n",
    "axes[1, 0].axvline(x=best_result['threshold'], color='black', linestyle='--', label=f'Optimal ({best_result[\"threshold\"]})')\n",
    "axes[1, 0].set_xlabel('Threshold')\n",
    "axes[1, 0].set_ylabel('Score')\n",
    "axes[1, 0].set_title('Metrics vs Threshold', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 5: Feature Importance\n",
    "top_features = importance_df.head(10)\n",
    "axes[1, 1].barh(top_features['feature'], top_features['importance'], color='steelblue')\n",
    "axes[1, 1].set_xlabel('Importance (Gain)')\n",
    "axes[1, 1].set_title('Top 10 Feature Importance', fontweight='bold')\n",
    "axes[1, 1].invert_yaxis()\n",
    "\n",
    "# Plot 6: Probability Distribution\n",
    "axes[1, 2].hist(y_probs[y_test == 0], bins=50, alpha=0.7, label='Non-Fraud', color='#2ecc71', density=True)\n",
    "axes[1, 2].hist(y_probs[y_test == 1], bins=50, alpha=0.7, label='Fraud', color='#e74c3c', density=True)\n",
    "axes[1, 2].axvline(x=best_result['threshold'], color='black', linestyle='--', label=f'Threshold ({best_result[\"threshold\"]})')\n",
    "axes[1, 2].set_xlabel('Predicted Probability')\n",
    "axes[1, 2].set_ylabel('Density')\n",
    "axes[1, 2].set_title('Probability Distribution by Class', fontweight='bold')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/xgboost_evaluation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ===== 11. SAVE MODEL =====\n",
    "model.save_model('models/xgboost_fraud_model.json')\n",
    "print(\"\\n✓ Model saved: models/xgboost_fraud_model.json\")\n",
    "print(\"✓ Visualization saved: outputs/xgboost_evaluation.png\")\n",
    "\n",
    "# ===== 12. COMPARISON SUMMARY =====\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: Neural Network vs XGBoost\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "                    Neural Network    XGBoost\n",
    "                    --------------    -------\n",
    "ROC-AUC:            0.5868            {roc_auc:.4f}\n",
    "PR-AUC:             0.0434            {pr_auc:.4f}\n",
    "Best F1:            0.0832            {best_result['f1']:.4f}\n",
    "Precision:          4.37%             {best_result['precision']*100:.2f}%\n",
    "Recall:             86.32%            {best_result['recall']*100:.2f}%\n",
    "False Positives:    508,936           {best_result['false_positives']:,}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns: ['transaction_id', 'timestamp', 'sender_account', 'receiver_account', 'amount', 'transaction_type', 'merchant_category', 'location', 'device_used', 'is_fraud', 'fraud_type', 'time_since_last_transaction', 'spending_deviation_score', 'velocity_score', 'geo_anomaly_score', 'payment_channel', 'ip_address', 'device_hash']\n",
      "\n",
      "Sample fraud vs non-fraud comparison:\n",
      "              amount  time_since_last_transaction  spending_deviation_score  \\\n",
      "is_fraud                                                                      \n",
      "False     357.420245                    -4.924667                  0.002159   \n",
      "True      397.088824                  -139.688917                 -0.134748   \n",
      "\n",
      "          velocity_score  geo_anomaly_score  \n",
      "is_fraud                                     \n",
      "False          10.465738           0.500260  \n",
      "True           10.151261           0.522773  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Faster: Read only first 100K rows for quick check\n",
    "df_sample = pd.read_csv('financial_fraud_detection_dataset.csv', nrows=100000)\n",
    "print(\"All columns:\", df_sample.columns.tolist())\n",
    "print(\"\\nSample fraud vs non-fraud comparison:\")\n",
    "print(df_sample.groupby('is_fraud').mean(numeric_only=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
